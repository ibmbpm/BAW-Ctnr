###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2020. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: workflow-workstreams
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 20.0.3
spec:
  appVersion: 20.0.3.2
  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""
  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:
    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "<Required>"
    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"
    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"
    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - admin.registrykey
    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is required
    sc_run_as_user:
    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-jobcontainer
        tag: 20.0.3-IF002
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-dbcompatibility-initcontainer
        tag: 20.0.3-IF002
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-initcontainer
        tag: 20.0.3-IF002
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/baw/dba-umsregistration-initjob
        tag: 20.0.3-IF002
      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent
    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca
    ## CP4A patterns or capabilities to be deployed.  This CR represents the "workflow-workstreams" pattern, which includes the following
    ## mandatory components: ban(Business Automation Navigator), ums (User Management Service), rr (Resource registry), app_engine( Application Engine) and optional components: bai
    sc_deployment_patterns: workflow-workstreams
    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: bai,ae_data_persistence
    sc_optional_components: bai,ae_data_persistence
    ## The deployment type as selected by the user.  Possible values are: demo, enterprise
    sc_deployment_type: enterprise
    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:
    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false
    ## For ROKS Ingress, provide TLS secret name for Ingress controller.
    sc_ingress_tls_secret_name: <Required>
    ## For OCP, this is used to create route, you should input a valid hostname in the required field.
    sc_deployment_hostname_suffix: "{{ meta.namespace }}.<Required>"
    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []
    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: "<Required>"
    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_initialization: false
    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_verification: false
    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "enterprise" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
    # Kafka client configuration for IBM Business Automation Insights and other ICP4A products.
    #
    # The customization of the following 4 parameters is "<Required>" only if you have
    # specificed "bai" as part of the sc_optional_components to specify that Business Automation
    # Insights must be installed.
    #
    # Otherwise, if Business Automation Insights is not being installed, there is no need to configure
    # these parameters and they can be kept empty.
    ##############################################################################################
    kafka_configuration:
      # A comma-separated list of hosts:port for connection to the Kafka cluster.
      # This parameter is mandatory for any Kafka configuration.
      bootstrap_servers: "<Required>"
      # The URL of the Kafka schema registry.
      # If the Business Automation Insights processor for custom events is configured, the value of this
      # parameter must provide the URL of the schema registry. Otherwise, it can be left empty.
      schema_registry_url:
      # The type of the Kafka schema registry.
      # Valid value: APICURIO. If not set, defaults to APICURIO. If set to any other value, the processing of
      # events using Avro schema in Business Automation Insights is not possible and the BAI Management
      # service is not deployed.
      schema_registry_type:
      # The value for the Kafka security.protocol property.
      # Valid values: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL. Default: SASL_SSL.
      security_protocol:
      # The value for the Kafka sasl.mechanism property.
      # Valid values: PLAIN, SCRAM-SHA-512. Default: PLAIN.
      sasl_mechanism:
      # If the Kafka server requires authentication or uses SSL communications, the value of this parameter
      # must provide the name of a Kubernetes secret that holds the following keys as base64-encoded strings:
      # kafka-username: Kafka username; leave empty if no authentication
      # kafka-password: Kafka password; leave empty if no authentication
      # kafka-server-certificate: server certificate for SSL communications; leave empty if SSL protocol is not used
      connection_secret_name:
  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.

    # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"
      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for the document object store (DOCS) datasource for CPE
    dc_os_datasources:
    - dc_database_type: "<Required>" ## Object store for FNDS DOCS. Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the GCD configuration above.
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOCS non-XA datasource name.  The default value is "FNDSDOCS".
      dc_common_os_datasource_name: "FNDSDOCS"
      ## The DOCS XA datasource name.  The default value is "FNDSDOCSXA".
      dc_common_os_xa_datasource_name: "FNDSDOCSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    - dc_database_type: "<Required>" ## The database configuration for the target object store (TOS) datasource for CPE
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The TOS non-XA datasource name.  The default value is "FNDSTOS".
      dc_common_os_datasource_name: "FNDSTOS"
      ## The TOS XA datasource name.  The default value is "FNDSTOSXA".
      dc_common_os_xa_datasource_name: "FNDSTOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    - dc_database_type: "<Required>" ## The database configuration for the design object store (DOS) datasource for CPE
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOS non-XA datasource name.  The default value is "FNDSDOS".
      dc_common_os_datasource_name: "FNDSDOS"
      ## The DOS XA datasource name.  The default value is "FNDSDOSXA".
      dc_common_os_xa_datasource_name: "FNDSDOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    - dc_database_type: "<Required>" ## object store for AEOS
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The AEOS non-XA datasource name.  The default value is "AEOS".
      dc_common_os_datasource_name: "AEOS"
      ## The AEOS XA datasource name.  The default value is "AEOSXA".
      dc_common_os_xa_datasource_name: "AEOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store AEOS for CPE.  For example: "AEOSDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for UMS (User Management Service)
    dc_ums_datasource:
      ## Provide the datasource configuration for oauth
      ## Possible dc_ums_oauth_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_oauth_alternate_hosts and dc_ums_oauth_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_oauth_host parameter
      dc_ums_oauth_type: "<Required>"
      ## Provide the database server name or IP address of the database server.
      dc_ums_oauth_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MSSQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_oauth_port: "<Required>"
      ## Provide the name of the database for UMS.  For example: "UMSDB"
      dc_ums_oauth_name: "<Required>"
      dc_ums_oauth_schema: OAuthDBSchema
      dc_ums_oauth_ssl: true
      dc_ums_oauth_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_oauth_driverfiles:
      ## For db2 HADR only
      dc_ums_oauth_alternate_hosts:
      dc_ums_oauth_alternate_ports:
      ## Provide the datasource configuration for the teamserver
      ## Possible dc_ums_teamserver_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_teamserver_alternate_hosts and dc_ums_teamserver_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_teamserver_host parameter
      dc_ums_teamserver_type: "<Required>"
      dc_ums_teamserver_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MS SQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_teamserver_port: "<Required>"
      ## Provide the name of the database for UMS teamserver.  For example: "UMSDB"
      dc_ums_teamserver_name: "<Required>"
      dc_ums_teamserver_ssl: true
      dc_ums_teamserver_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_teamserver_driverfiles:
      ## For db2 HADR only
      dc_ums_teamserver_alternate_hosts:
      dc_ums_teamserver_alternate_ports:
    ## The database configuration for ICN (Navigator) - aka BAN (Business Automation Navigator)
    dc_icn_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the
      ## GCD and object store configuration above.
      dc_database_type: "<Required>"
      ## Provide the ICN datasource name.  The default value is "ECMClientDS".
      dc_common_icn_datasource_name: "ECMClientDS"
      database_servername: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## Provide the name of the database for ICN (Navigator).  For example: "ICNDB"
      database_name: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_icn_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
  ########################################################################
  ########   IBM Business Automation Workflow configuration     ########
  ########################################################################
  baw_configuration:
  - ## For each instance, baw_configuration.name and baw_configuration.name.hostname must have different values.
    name: instance1 ## The baw_configuration is a list. You can deploy multiple instances of Workflow server and assign different configurations for each instance.
    ## If config the Process Portal for a federated environment and integrate with intelligent task prioritization
    host_federated_portal: true
    ## Workflow server service type.
    service_type: "Route"
    ## Workflow server hostname
    hostname: ""
    ## Workflow server port
    port: 443
    ## Workflow server nodeport
    nodeport: 30026
    ## Workflow server environment type. The possible value are "Development" or "Test" or "Staging" or "Production"
    env_type: "Production"
    ## Workflow server capability
    capabilities: "workflow,workstreams"
    ## Workflow server replica count
    replicas: 2
    ## Provide Workflow server default administrator ID
    admin_user: "<Required>"
    ## The name of Workflow server admin secret, the secret name is optional, if the secret name is null, default secret named {{ meta.name }}-<instance-name>-baw-admin-secret will be generated
    admin_secret_name: "{{ meta.name }}-instance1-baw-admin-secret"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false
    # For scenario that customer has implemented their own Portal. E,g https://portal.mycompany.com
    customized_portal_endpoint: ""
    federated_portal:
      ## Content security policy additional origins for federate on premise BAW systems. E.g ["https://on-prem-baw1","https://on-prem-baw2"]
      content_security_policy_additional_origins: []
    external_connection_timeout: ""
    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:
    tls:
      ## Workflow server TLS secret that contains tls.key and tls.crt.
      tls_secret_name: ibm-baw-tls
      ## Workflow server TLS trust list.
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic baw_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want Workflow server to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic baw_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:
    image:
      ## Workflow image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server
      ## Image tag for Workflow server container
      tag: 20.0.3-IF002
      ## Pull policy for Workflow container
      pullPolicy: IfNotPresent
    pfs_bpd_database_init_job:
      ## Database initialization image repository URL for Process Federation Server
      repository: cp.icr.io/cp/cp4a/baw/pfs-bpd-database-init-prod
      ## Image tag for database initialization for Process Federation Server
      tag: 20.0.3-IF002
      ## Pull policy for Process Federation Server database initialization image
      pullPolicy: IfNotPresent
    upgrade_job:
      ## Workflow server database handling image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Image tag for Workflow server database handling
      tag: 20.0.3-IF002
      ## Pull policy for Workflow server database handling
      pullPolicy: IfNotPresent
    bas_auto_import_job:
      ## BAS toolkit init image repository URL
      repository: cp.icr.io/cp/cp4a/baw/toolkit-installer
      ## Image tag for BAS toolkit init image
      tag: 20.0.3-IF002
      ## Pull policy for BAS toolkit init image
      pullPolicy: IfNotPresent
    ibm_workplace_job:
      ## IBM Workplace deployment job image repository URL
      repository: cp.icr.io/cp/cp4a/baw/iaws-ibm-workplace
      ## Image tag for IBM Workplace deployment job image
      tag: 20.0.3-IF002
      ## Pull policy for IBM Workplace deployment job image
      pull_policy: IfNotPresent
    ## The database configuration for Workflow server
    database:
      ## Whether to enable Secure Sockets Layer (SSL) support for the Workflow server database connection
      enable_ssl: true
      ## Secret name for storing the database TLS certificate when enable SSL connections to the Workflow server databae engine. Required only when enable_ssl is true
      db_cert_secret_name: "<Required>"
      ## Workflow server database type, Possible values are: db2, oracle, postgresql
      type: "<Required>"
      ## Workflow server database server name
      server_name: "<Required>"
      ## Workflow server database name
      database_name: "<Required>"
      ## Workflow server database port. For DB2, the default value is "50000"
      port: "<Required>"
      ## Workflow server database secret name which include the database user name and password.
      secret_name: "<Required>"
      # If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      jdbc_url:
      # Set to true if using custom JDBC drivers (For example using Oracle, PostgreSQL or some special DB2 driver)
      use_custom_jdbc_drivers: false
      # The PVC name which bind to the PV which have the custom JDBC driver files stored
      custom_jdbc_pvc:
      # The custom JDBC driver files set
      jdbc_driver_files: 'db2jcc4.jar db2jcc_license_cisuz.jar db2jcc_license_cu.jar'
      ## Workflow server database connect pool maximum number of physical connections
      cm_max_pool_size: 200
      dbcheck:
        ## The maximum waiting time (seconds) to check the database intialization status
        wait_time: 900
        ## The interval time (seconds) to check.
        interval_time: 15
      hadr:
        ## Database standby host for high availability disaster recovery (HADR)
        ## To enable database HADR, configure both standby host and port
        standbydb_host:
        ## Database standby port for HADR
        standbydb_port:
        ## Retry interval for HADR
        retryinterval:
        ## Maximum retries for HADR
        maxretries:
    ## The configurations for content integration
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container
        tag: 20.0.3-IF002
        ## Pull policy for content integration container.
        pull_policy: IfNotPresent
      ## Domain name for content integration
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration
      object_store_name: "DOCS"
      ## Admin secret for content integration
      cpe_admin_secret: ""
    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: 20.0.3-IF002
        ## Pull policy for CASE init job container.
        pull_policy: IfNotPresent
      ## Domain name for CASE
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE
      object_store_name_dos: "DOS"
      ## Target Object Store name of CASE
      object_store_name_tos: "TOS"
      ## Connection point name for Target Object Store
      connection_point_name_tos: "cpe_conn_tos"
      ## Name of the target environment/project area to register with the case components and associate with an IBM Content Navigator desktop
      target_environment_name: "target_env"
      ## PVC name for CASE network shared directory
      network_shared_directory_pvc: "{{ navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore
        | default('icn-pluginstore', true) }}"
      ## The custom package names if need to install custom package, the value format like "package1.zip, package2,zip"
      custom_package_names: ""
      ## The custom extension names if need to install custom extension, the value format like "extension1.zip, extension2,zip"
      custom_extension_names: ""
      ## The event emitter settings if you want to enable Case Event Emitter
      event_emitter:
        date_sql:
        logical_unique_id:
        solution_list:
        emitter_batch_size:
        process_pe_events:
    ## Workflow center configuration
    workflow_center:
      ## The URL of workflow center
      url: ""
      # The secret name of workflow center that contains username and password
      secret_name: ""
      # The hearbeat interval(seconds) to connect to workflow center
      heartbeat_interval: 30
      webpd_url: ""
    ## Application engine configuration, because application engine is an array,
    ## when there is only one Application engine deployed along with this CR, below three parameters are not required.
    ## when there is more then one application engine deployed, below three parameters are required.
    appengine:
      ## App Engine hostname
      hostname: ""
      ## App Engine port
      port: "443"
      ## App Engine admin secret name
      admin_secret_name: ""
    ## The configuration for Java Messaging Service(JMS)
    jms:
      image:
        ## Image name for Java Messaging Service container
        repository: cp.icr.io/cp/cp4a/baw/jms
        ## Image tag for Java Messaging Service container
        tag: 20.0.3-IF002
        ## Pull policy for Java Messaging Service container
        pull_policy: IfNotPresent
      tls:
        ## TLS secret name for Java Message Service (JMS)
        tls_secret_name: ibm-jms-tls-secret
      resources:
        limits:
          ## Memory limit for JMS configuration
          memory: "2Gi"
          ## CPU limit for JMS configuration
          cpu: "1000m"
        requests:
          ## Requested amount of memory for JMS configuration
          memory: "512Mi"
          ## Requested amount of CPU for JMS configuration
          cpu: "200m"
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname
          }}"
      ## Default values for liveness probes. Modify these values to meet your requirements.
      liveness_probe:
        initial_delay_seconds: 180
        period_seconds: 20
        timeout_seconds: 10
        failure_threshold: 3
        success_threshold: 1
      ## Default values for rediness probes. Modify these values to meet your requirements.
      readiness_probe:
        initial_delay_seconds: 30
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6
        success_threshold: 1
    ## Resource configuration for init job
    resources_init:
      limits:
        ## CPU limit
        cpu: "500m"
        ## Memory limit
        memory: 256Mi
      requests:
        ## Requested amount of CPU
        cpu: "200m"
        ## Requested amount of memory
        memory: 128Mi
    ## Resource configuration for heavy init job such as database init job
    resources_init_heavy_job:
      limits:
        ## CPU limit
        cpu: 1
        ## Memory limit
        memory: 1536Mi
      requests:
        ## Requested amount of CPU
        cpu: "500m"
        ## Requested amount of memory
        memory: 512Mi
    ## Resource configuration
    resources:
      limits:
        ## CPU limit for Workflow server.
        cpu: 4
        ## Memory limit for Workflow server
        memory: 3Gi
      requests:
        ## Requested amount of CPU for Workflow server
        cpu: "500m"
        ## Requested amount of memory for Workflow server.
        memory: 1048Mi
    ## liveness and readiness probes configuration
    probe:
      ws:
        liveness_probe:
          ## Number of seconds after the Workflow server container starts before the liveness probe is initiated
          initial_delay_seconds: 300
          ## Number of seconds to wait before the next probe.
          period_seconds: 10
          ## Number of seconds after which the probe times out.
          timeout_seconds: 10
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 3
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
        readinessProbe:
          ## Number of seconds after the Workflow server container starts before the readiness probe is initiated
          initial_delay_seconds: 240
          ## Number of seconds to wait before the next probe.
          period_seconds: 5
          ## Number of seconds after which the probe times out.
          timeout_seconds: 5
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 6
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format.
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      # Maximum number of log files that are kept before the oldest file is removed
      max_files: 10
      # The maximum size (in MB) that a log file can reach before it is rolled.
      max_filesize: 50
    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_dumpstore
      use_dynamic_provisioning: true
      ## The persistent volume claim for logs
      existing_pvc_for_logstore: ""
      ## The minimum size of the persistent volume used mounted as log store
      size_for_logstore: "10Gi"
      ## The persistent volume claim for dump files
      existing_pvc_for_dumpstore: ""
      ## The minimum size of the persistent volume used mounted as dump store
      size_for_dumpstore: "10Gi"
      ## The persistent volume claim for generic files
      existing_pvc_for_filestore: ""
      ## The minimum size of the persistent volume used mounted as generic file store
      size_for_filestore: "10Gi"
    ## autoscaling
    autoscaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      target_cpu_utilization_percentage: 80
    ## customize environment settings
    environment_config:
      ## Whether to show intelligent task prioritization service toggle button in web UI to allow task user enable/disable task prioritization service
      show_task_prioritization_service_toggle: false
      ## By default, it is false. If 'always_run_task_prioritization_service' is set to true, the value of the 'show_task_prioritization_service_toggle' is ignored and the toggle is not displayed to the user.
      always_run_task_prioritization_service: false
    ## federation config
    federation_config:
      workflow_server:
        ## Number of primary shards of the Elasticsearch index used to store workflow server data
        index_number_of_shards: 3
        ## Number of shards replicas of the Elasticsearch index used to store workflow server data
        index_number_of_replicas: 1
      case_manager:
      - object_store_name: TOS
        ## Number of primary shards of the Elasticsearch index used to store Case Manager object store data
        index_number_of_shards: 3
        ## Number of shards replicas of the Elasticsearch index used to store Case Manager object store data
        index_number_of_replicas: 1
    ## JVM options separated with space, for example: -Dtest1=test -Dtest2=test2
    jvm_customize_options:
    ##  Workflow server custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    liberty_custom_xml:
    ##  Workflow server custom XML secret name that contains custom configuraiton in Liberty server.xml
    custom_xml_secret_name:
    ##  Workflow server Lombardi custom XML secret name that contains custom configuraiton in 100Custom.xml
    lombardi_custom_xml_secret_name:
    ##  IBM Business Automation Insights integration configuration
    business_event:
      enable: false
      enable_task_record: true
      ## set it to true when Business Automation Machine Learning Server configuration is enabled as well
      enable_task_api: false
      subscription:
      - {'app_name': '*', 'version': '*', 'component_type': '*', 'component_name': '*',
        'element_type': '*', 'element_name': '*', 'nature': '*'}
  ##################################################################################
  ########   IBM Business Automation Machine Learning Server configuration  ########
  ##################################################################################
  baml_configuration:
    ## Intelligent Task Prioritization configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true
    intelligent_task_prioritization:
      ## Intelligent Task Prioritization replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Intelligent Task Prioritization container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      ## Image name for Intelligent Task Prioritization container
      image:
        repository: cp.icr.io/cp/cp4a/baw/bui-task-prioritization
        ## Image tag for Intelligent Task Prioritization container
        tag: 20.0.3-IF002
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for Intelligent Task Prioritization container
          cpu: "2"
          ## Memory limit for Intelligent Task Prioritization container
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for Intelligent Task Prioritization container
          cpu: "500m"
          ## Requested amount of memory for Intelligent Task Prioritization container
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_trained_pipelines
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
        ## The persistent volume claim for Intelligent Task Prioritization trained piplines files
        existing_pvc_for_trained_pipelines: ""
        ## The minimum size of the persistent volume used mounted as Intelligent Task Prioritization trained piplines files
        size_for_trained_pipelines: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
    ## Workforce Insights configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true and bai_configuration.bpmn.forceElasticsearchTimeseries to true
    workforce_insights:
      ## Workforce Insights replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Workforce Insights pod container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      image:
        repository: cp.icr.io/cp/cp4a/baw/workforce-insights
        tag: 20.0.3-IF002
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for workforce insights
          cpu: "2"
          ## Memory limit for workforce insights
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for workforce insights
          cpu: "500m"
          ## Requested amount of memory for workforce insights
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
  ########################################################################
  ########   IBM Process Federation Server configuration          ########
  ########################################################################
  pfs_configuration:
    ## Process Federation Server hostname
    hostname: ""
    ## Process Federation Server port
    port: 443
    ## How the HTTPS endpoint service should be published. Possible values are ClusterIP, NodePort, Route
    service_type: Route
    ## If use the external elasticsearch server, provide the following configuration
    elasticsearch:
      ## The endpoint of external elasticearch, such as: https://<external_es_host>:<external_es_port>
      endpoint: ""
      ## The external elasticsearch administrative secret that contains the username, password and .htpasswd.
      admin_secret_name: ""
      connect_timeout: 10s
      read_timeout: 30s
      thread_count: 0
    image:
      ## Process Federation Server image
      repository: cp.icr.io/cp/cp4a/baw/pfs-prod
      ## Process Federation Server image tag
      tag: 20.0.3-IF002
      ## Process Federation Server image pull policy
      pull_policy: IfNotPresent
    ## Number of initial Process Federation Server pods
    replicas: 1
    ## Service account name for Process Federation Server pod
    service_account:
    ## Whether Kubernetes can (soft) or must not (hard) deploy Process Federation Server pods onto the same node. Possible values are "soft" and "hard".
    anti_affinity: hard
    ## Whether to enable default security roles  and possible values are: true and false
    enable_default_security_roles: true
    ## Name of the secret containing the Process Federation Server administration passwords, such as ltpaPassword, oidcClientPassword, sslKeyPassword
    admin_secret_name: ibm-pfs-admin-secret
    ## Name of the secret containing the files that will be mounted in the /config/configDropins/overrides folder
    config_dropins_overrides_secret: ""
    ## Name of the secret containing the files that will be mounted in the /config/resources/security folder
    resources_security_secret: ""
    ## Name of the custom libraries containing the files that will be mounted in the /config/resources/libs folder
    custom_libs_pvc: ""
    ## Whether to enable notification server and possible values are: true and false
    enable_notification_server: true
    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false
    tls:
      ## Existing TLS secret containing tls.key and tls.crt
      tls_secret_name:
      ## Existing TLS trust secret list
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic pfs_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want PFS server to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic pfs_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:
    resources:
      requests:
        ## Requested amount of CPU for PFS configuration
        cpu: 500m
        ## Requested amount of memory for PFS configuration
        memory: 512Mi
      limits:
        ## CPU limit for PFS configuration
        cpu: 2
        ## Memory limit for PFS configuration
        memory: 4Gi
    liveness_probe:
      ## Number of seconds after Process Federation Server container starts before the liveness probe is initiated
      initial_delay_seconds: 300
    readiness_probe:
      ## Number of seconds after Process Federation Server container starts before the readiness probe is initiated
      initial_delay_seconds: 240
    saved_searches:
      ## Name of the Elasticsearch index used to store saved searches
      index_name: ibmpfssavedsearches
      ## Number of shards of the Elasticsearch index used to store saved searches
      index_number_of_shards: 3
      ## Number of replicas (pods) of the Elasticsearch index used to store saved searches
      index_number_of_replicas: 1
      ## Batch size used when retrieving saved searches
      index_batch_size: 100
      ## Amount of time before considering an update lock as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      update_lock_expiration: 5m
      ## Amount of time before considering a unique constraint as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      unique_constraint_expiration: 5m
    security:
      sso:
        ## The ssoDomainNames property of the <webAppSecurity> tag
        domain_name:
        ## The ssoCookieName property of the <webAppSecurity> tag
        cookie_name: "ltpatoken2"
        ltpa:
          ## The keysFileName property of the <ltpa> tag
          filename: "ltpa.keys"
          ## The expiration property of the <ltpa> tag
          expiration: "120m"
          ## The monitorInterval property of the <ltpa> tag
          monitor_interval: "60s"
      ## The sslProtocol property of the <ssl> tag used as default SSL config
      ssl_protocol: SSL
    executor:
      ## Value of the maxThreads property of the <executor> tag
      max_threads: "80"
      ## Value of the coreThreads property of the <executor> tag
      core_threads: "40"
    rest:
      ## Value of the userGroupCheckInterval property of the <ibmPfs_restConfig> tag
      user_group_check_interval: "300s"
      ## Value of the systemStatusCheckInterval property of the <ibmPfs_restConfig> tag
      system_status_check_interval: "60s"
      ## Value of the bdFieldsCheckInterval property of the <ibmPfs_restConfig> tag
      bd_fields_check_interval: "300s"
    custom_env_variables:
      ## Names of the custom environment variables defined in the secret referenced in pfs.customEnvVariables.secret
      names:
      # - name: MY_CUSTOM_ENVIRONMENT_VARIABLE
      ## Secret holding custom environment variables
      secret:
    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      storage:
        ## Use Dynamic Provisioning for PFS Logs Data Storage
        use_dynamic_provisioning: true
        ## The minimum size of the persistent volume used mounted as PFS Liberty server /logs folder
        size: 5Gi
        ## Storage class of the persistent volume used mounted as PFS Liberty server /logs folder
        storage_class: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname
          }}"
        existing_pvc_name: ""
    ## When PFS is deployed in a environment that includes the Resource Registry ,
    ## the following additional parameters can be used to configure the integration between PFS and the Resource Registry
    dba_resource_registry:
      ## Time to live of the lease that creates the PFS entry in the DBA Resource Registry, in seconds.
      lease_ttl: 120
      ## The interval at which to check that PFS is running, in seconds.
      pfs_check_interval: 10
      ## The number of seconds after which PFS will be considered as not running if no connection can be perfomed
      pfs_connect_timeout: 10
      ## The number of seconds after which PFS will be considered as not running if has not yet responded
      pfs_response_timeout: 30
      ## The key under which PFS should be registered in the DBA Service Registry when running
      pfs_registration_key: /dba/appresources/IBM_PFS/PFS_SYSTEM
      resources:
        limits:
          ## Memory limit for PFS and RR integration pod
          memory: '512Mi'
          ## CPU limit for PFS and RR integration pod
          cpu: '500m'
        requests:
          ## Requested amount of memory for PFS and RR integration pod
          memory: '512Mi'
          ## Requested amount of CPU for PFS and RR integration pod
          cpu: '200m'
  ########################################################################
  ########   Embedded Elasticsearch configuration                 ########
  ########################################################################
  elasticsearch_configuration:
    es_image:
      ## Elasticsearch image
      repository: cp.icr.io/cp/cp4a/baw/pfs-elasticsearch-prod
      ## Elasticsearch image tag
      tag: 20.0.3-IF002
      ## Elasticsearch image pull policy
      pull_policy: IfNotPresent
    es_init_image:
      ## The image used by the privileged init container to configure Elasticsearch system settings.
      ## This value is only relevant if elasticsearch_configuration.privileged is set to true
      repository: cp.icr.io/cp/cp4a/baw/pfs-init-prod
      ## The image tag for Elasticsearch init container
      tag: 20.0.3-IF002
      ## The pull policy for Elasticsearch init container
      pull_policy: IfNotPresent
    es_nginx_image:
      ## The name of the Nginx docker image to be used by Elasticsearch pods
      repository: cp.icr.io/cp/cp4a/baw/pfs-nginx-prod
      ## The image tag of the Nginx docker image to be used by Elasticsearch pods
      tag: 20.0.3-IF002
      ## The pull policy for the Nginx docker image to be used by Elasticsearch pods
      pull_policy: IfNotPresent
    ## Number of initial Elasticsearch pods
    replicas: 1
    ## How the HTTPS endpoint service should be published. The possible values are ClusterIP and NodePort
    service_type: ClusterIP
    ## The port to which the Elasticsearch server HTTPS endpoint will be exposed externally.
    ## This parameter is relevant only if elasticsearch_configuration.service_type is set to NodePort
    external_port:
    ## The elasticsearch admin secret that contains the username, password and .htpasswd.
    ## If not provided, the defualt admin secret named "{{ meta.name }}-elasticsearch-admin-secret" is used.
    admin_secret_name:
    ## Whether Kubernetes "may" (soft) or "must not" (hard) deploy Elasticsearch pods onto the same node
    ## The possible values are "soft" and "hard"
    anti_affinity: hard
    ## The Elasticsearch pods require the hosting worker nodes to be configured to:
    ## - disable memory swapping by setting the sysctl value vm.swappiness to 1.
    ## - increase the limit on the number of open files descriptors for the user running Elasticsearch by setting sysctl value vm.max_map_count to 65,536 or higher.
    ## When set to true, a privileged init container will execute the appropriate sysctl commands to update the worker node configuration to match Elasticsearch requirements.
    ## When set to false, you must ask the cluster administrator to change the memory swapping and descriptor properties on each worker node.
    privileged: false
    ## If elasticsearch_configuration.privileged is set to true, you must create a service account that has the privileged SecurityContextConstraint to allow running privileged containers. Refer to Knowledge Center for more info.
    ## If elasticsearch_configuration.service_account not set, default service account "{{ meta.name }}-elasticsearch-service-account" will be used.
    service_account: "<Required>"
    ## Initial delay for liveness and readiness probes of Elasticsearch pods
    probe_initial_delay: 90
    ## The JVM heap size to allocate to each Elasticsearch pod
    heap_size: "1024m"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false
    resources:
      limits:
        ## Memory limit for Elasticsearch configuration
        memory: "2Gi"
        ## CPU limit for Elasticsearch configuration
        cpu: "1000m"
      requests:
        ## Requested amount of memory for Elasticsearch configuration
        memory: "2Gi"
        ## Requested amount of CPU for Elasticsearch configuration
        cpu: "100m"
    storage:
      ## If persistent the elasticsearch data. Set to false for non-production or trial-only deployment.
      persistent: true
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 10Gi
      ## Storage class name for Elasticsearch persistent storage
      storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname
        }}"
    snapshot_storage:
      ## If persistent the elasticsearch snapshot storage. Set to true for production deployment.
      enabled: false
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 30Gi
      ## Storage class name for Elasticsearch persistent snapshot storage
      storage_class_name: ""
      ## By default, a new persistent volume claim is be created. Specify an existing claim here if one is available.
      existing_claim_name: ""
  ########################################################################
  ########  IBM FileNet Content Manager initialize configuration  ########
  ########################################################################
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      ## Provide a name for the domain
      domain_name: "P8DOMAIN"
      ## The encryption strength
      encryption_key: "128"
    ic_ldap_creation:
      ## Administrator user
      ic_ldap_admin_user_name:
      - "CEAdmin"
      ## Administrator group
      ic_ldap_admins_groups_name:
      - "P8Administrators"
      ## Name of the LDAP directory
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      - ## Display name for the document object store to create
        oc_cpe_obj_store_display_name: "DOCS" ## Configuration for the document object store
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOCS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOCS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOCS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOCSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "docs_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false
      - ## Display name for the design object store to create
        oc_cpe_obj_store_display_name: "DOS" ## Configuration for the design object store
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "dos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 2
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false
      - ## Display name for the target object store to create
        oc_cpe_obj_store_display_name: "TOS" ## Configuration for the target object store
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "TOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "tos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "cpe_conn_tos"
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false
      - ## Display name for the application engine object store to create
        oc_cpe_obj_store_display_name: "AEOS" ## Configuration for the application engine object store
        ## Symbolic name for the application engine object store to create
        oc_cpe_obj_store_symb_name: "AEOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "AEOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "AEOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "AEOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/osae_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "aeos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false
  ########################################################################
  ########      IBM Business Automation Insights configuration    ########
  ########################################################################
  bai_configuration:
    imageCredentials:
      registry: cp.icr.io/cp/cp4a
    # Set to true to automatically create the OpenShift routes when sc_deployment_platform is set
    # to OCP or ROKS.
    createRoutes: false
    # Set to true to enable the Flink job for sending events to HDFS.
    ingestion:
      install: false
    # Set to false to disable the Flink job for BAW.
    bpmn:
      install: true
    # Set to true to enable the Flink job for BAWAdv.
    bawadv:
      install: false
    # Set to false to disable the Flink job for ICM.
    icm:
      install: true
    # Set to true to enable the Flink job for ODM.
    odm:
      install: false
    # Set to true to enable the Flink job for Content.
    content:
      install: false
  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory"
    lc_selected_ldap_type: "<Required>"
    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"
    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"
    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret
    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"
    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true
    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"
    ## The LDAP user name attribute.  One possible value is "*:cn" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"
    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"
    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"
    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"
    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"
    ## The LDAP group membership search filter string.  One possible value is "(&(cn=%v)(|(objectclass=groupOfNames)(objectclass=groupOfUniqueNames)(objectclass=groupOfURLs)))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"
    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"
    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(samAccountName=%v)(objectClass=user))"
    #   lc_group_filter: "(&(samAccountName=%v)(objectclass=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
  ########################################################################
  ########   IBM Business Automation Navigator configuration      ########
  ########################################################################
  navigator_configuration:
    ## Navigator secret that contains user credentials for LDAP and database
    ban_secret_name: ibm-ban-secret
    ## The architecture of the cluster.  This is the default for Linux and should not be changed.
    arch:
      amd64: "3 - Most preferred"
    ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
    ## it is recommended to have 2 or more.
    replica_count: 2
    ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
    image:
      ## The default repository is the IBM Entitled Registry
      repository: cp.icr.io/cp/cp4a/ban/navigator-sso
      tag: ga-309-icn-if001
      ## This will override the image pull policy in the shared_configuration.
      pull_policy: IfNotPresent
    ## Logging for workloads.  This is the default setting.
    log:
      format: json
    ## This is the initial default resource requests.  If more resources are needed,
    ## make the changes here to meet your requirement.
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1536Mi
    ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
    ## this settings to meet your requirement.
    auto_scaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      ## This is the default cpu percentage before autoscaling occurs.
      target_cpu_utilization_percentage: 80
    ## Below are the default ICN Production settings.  Make the necessary changes as you see fit.
    icn_production_setting:
      timezone: Etc/UTC
      jvm_initial_heap_percentage: 40
      jvm_max_heap_percentage: 66
      jvm_customize_options:
      icn_jndids_name: ECMClientDS
      icn_schema: ICNDB
      icn_table_space: ICNDB
      allow_remote_plugins_via_http: false
    ## Default settings for monitoring
    monitor_enabled: false
    ## Default settings for logging
    logging_enabled: false
    ## Persistent Volume Claims for Navigator.  The Operator will create the PVC using the names below by default.
    datavolume:
      existing_pvc_for_icn_cfgstore: "icn-cfgstore"
      existing_pvc_for_icn_logstore: "icn-logstore"
      existing_pvc_for_icn_pluginstore: "icn-pluginstore"
      existing_pvc_for_icnvw_cachestore: "icn-vw-cachestore"
      existing_pvc_for_icnvw_logstore: "icn-vw-logstore"
      existing_pvc_for_icn_aspera: "icn-asperastore"
    ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
    probe:
      readiness:
        initial_delay_seconds: 120
        period_seconds: 5
        timeout_seconds: 10
        failure_threshold: 6
      liveness:
        initial_delay_seconds: 600
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6
    ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
    image_pull_secrets:
      name: "admin.registrykey"
  ########################################################################
  ########   IBM User and Group Management Service configuration  ########
  ########################################################################
  ums_configuration:
    existing_claim_name:
    dedicated_pods: true
    service_type: Route
    routes_ingress_annotations:
    # your external UMS host name, only required if there is no sc_deployment_hostname_suffix given
    hostname:
    port: 443
    images:
      ums:
        repository: cp.icr.io/cp/cp4a/ums/ums
        tag: 20.0.3-IF002
    admin_secret_name: ibm-dba-ums-secret
    ## optional for secure communication with UMS
    external_tls_secret_name:
    ## optional for secure communication with UMS
    external_tls_ca_secret_name:
    ## optional for secure communication with UMS
    external_tls_teams_secret_name:
    ## optional for secure communication with UMS
    external_tls_scim_secret_name:
    ## optional for secure communication with UMS
    external_tls_sso_secret_name:
    use_custom_jdbc_drivers: false
    use_custom_binaries: false
    custom_secret_name:
    oauth:
      ## optional: full DN of an LDAP group that is authorized to manage OIDC clients, in addition to primary admin from admin secret
      client_manager_group:
      ## optional: full DN of an LDAP group that is authorized to manage app_tokens, in addition to primary admin from admin secret
      token_manager_group:
      ## optional: lifetime of OAuth access_tokens. default is 7200s
      access_token_lifetime:
      ## optional: lifetime of app-tokens. default is 366d
      app_token_lifetime:
      ## optional: lifetime of app-passwords. default is 366d
      app_password_lifetime:
      ## optional: maximum number of app-tokens or app-passwords per client. default is 100
      app_token_or_password_limit:
      ## optional: encoding / encryption when storing client secrets in OAuth database. Default is xor for compatibility. Recommended value is PBKDF2WithHmacSHA512
      client_secret_encoding:
    #### If dedicated_pods is set to false, the UMS capabilities sso, scim and teamserver
    #### run in the same pods and share this configuration
    replica_count: 2
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    autoscaling:
      enabled: true
      min_replicas: 2
      max_replicas: 5
      target_average_utilization: 98
    custom_xml:
    logs:
      traceSpecification: "*=info"
    #### If dedicated_pods is set to true, the UMS capabilities sso, scim and teamserver
    #### run in dedicated pods and are configured separately

    # Configuration for sso pods
    sso:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"
    # configuration for scim pods
    scim:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"
    # configuration for teamserver pods
    teamserver:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"
  ##################################################################
  ########   Resource Registry configuration                ########
  ##################################################################
  resource_registry_configuration:
    # If you inputed hostname and port here. They will be used always
    # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
    # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
    # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
    # For non pattern mode you must assign a valid hostname and port here
    hostname: "{{ 'rr.' + shared_configuration.sc_deployment_hostname_suffix }}"
    port: 443
    images:
      pull_policy: IfNotPresent
      resource_registry:
        repository: cp.icr.io/cp/cp4a/aae/dba-etcd
        tag: 20.0.3-IF002
    admin_secret_name: resource-registry-admin-secret
    replica_size: 3
    probe:
      liveness:
        initial_delay_seconds: 60
        period_seconds: 10
        timeout_seconds: 5
        success_threshold: 1
        failure_threshold: 3
      readiness:
        initial_delay_seconds: 10
        period_seconds: 10
        timeout_seconds: 5
        success_threshold: 1
        failure_threshold: 3
    resource:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "100m"
        memory: "128Mi"
    auto_backup:
      enable: true
      minimal_time_interval: 300
      pvc_name: "{{ meta.name }}-dba-rr-pvc"
      dynamic_provision:
        enable: true
        size: 3Gi
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname
          }}"
  #############################################################################
  ######## IBM Business Automation Application server  configurations  ########
  ##  This section contains the configurations for                           ##
  ##  * App Engine Server                                                    ##
  ##  it's the optional component and will be installed when                 ##
  ##  patterns include: application, workflow, workstreams,                  ##
  ##                    workflow-workstreams or document_processing          ##
  #############################################################################
  application_engine_configuration:
  - name: workspace ## The application_engine_configuration is a list, you can deploy multiple instances of AppEngine, you can assign different configurations for each instance.
    images:
      pull_policy: IfNotPresent
      solution_server:
        repository: cp.icr.io/cp/cp4a/aae/solution-server
        tag: 20.0.3-IF002
      db_job:
        repository: cp.icr.io/cp/cp4a/aae/solution-server-helmjob-db
        tag: 20.0.3-IF002
    # If you inputed hostname and port here. They will be used always
    # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
    # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
    # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
    # For non pattern mode you must assign a valid hostname and port here
    hostname: "{{ 'ae-workspace.' + shared_configuration.sc_deployment_hostname_suffix
      }}"
    port: 443
    # Inside the admin secret. There are two must fields
    admin_secret_name: "{{ meta.name }}-workspace-aae-app-engine-admin-secret"
    #-----------------------------------------------------------------------
    # The app engine admin Secret template will be
    #-----------------------------------------------------------------------
    # apiVersion: v1
    # stringData:
    #   AE_DATABASE_PWD: "<Your database password>"
    #   AE_DATABASE_USER: "<Your database username>"
    #   REDIS_PASSWORD: "<Your Redis server password>"
    # kind: Secret
    # metadata:
    #   name: icp4adeploy-workspace-aae-app-engine-admin-secret
    # type: Opaque
    #-----------------------------------------------------------------------
    # The default admin user id for application engine
    # The user ID should be bootstrap admin ID for IBM Business Automation Navigator. It is case sensitive.
    # The same ID should be a User Management Service (UMS) admin user also.
    admin_user: <Required>
    external_tls_secret:
    external_connection_timeout: 90s
    replica_size: 2
    # data_persistence is for Business Automation Application Data Persistence(ae_data_persistence).
    # If you are using pattern mode, the shared_configuration.sc_deployment_patterns contains value and sc_optional_components contains ae_data_persistence, then you do not need input any value to data_persistence.enable, it is enabled by default.
    # If you are using non-pattern mode, you can set data_persistence.enable to true to enable it.
    # Notes: ae_data_persistence is not supported in demo pattern mode and when AE is as playback server
    data_persistence:
      enable:
      ## If ae_data_persistence is enabled. Then you must input one CPE object store name. If you keep the default object store configuration. Then the default name filled should be AEOS.
      object_store_name: "AEOS"
    ## optional when the database type is Db2, must required when the database type is Oracle, PostgreSQL.
    use_custom_jdbc_drivers: false
    service_type: Route
    autoscaling:
      enabled: false
      max_replicas: 5
      min_replicas: 2
      target_cpu_utilization_percentage: 80
    server_identifier: ""
    database:
      # AE Database host name or IP when the database type is Db2, PostgreSQL.
      host: <Required>
      # AE Database name when the database type is Db2, PostgreSQL.
      #Provide the database name for runtime application engine use
      #Please pay attention that if you selected authoring environment also.
      #The database used by playback server and this one should be different
      name: <Required>
      # AE database port number when the database type is Db2, PostgreSQL.
      port: <Required>
      ## If you setup Db2 HADR or PostgreSQL Connection Fail-over and want to use it, you need to configure alternative_host and alternative_port, or else, leave is as blank.
      ## If more than one server name is specified, delimit the server names with commas (,). The number of values that is specified for alternative_host must match the number of values that is specified for alternative_port.
      alternative_host:
      alternative_port:
      ## Only Db2, Oracle, PostgreSQL are supported.
      type: db2
      ## Required only when the database type is Oracle, both ssl and non-ssl. The format must be purely Oracle descriptor like (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=<your database host/IP>)(PORT=<your database port>))(CONNECT_DATA=(SERVICE_NAME=<your Oracle service name>))).
      oracle_url_without_wallet_directory:
      enable_ssl: true
      ## Required only when type is Oracle and enable_ssl is true. The format must be purely oracle descriptor. SSO wallet directory must be specified and fixed to (MY_WALLET_DIRECTORY=/shared/resources/oracle/wallet).
      oracle_url_with_wallet_directory:
      ## Required only when enable_ssl is true, when the database type is Db2, Oracle or PostgreSQL
      db_cert_secret_name: <Required>
      ## Required only when type is oracle and enable_ssl is true.
      oracle_sso_wallet_secret_name:
      ## Optional. If it is empty, the DBASB is default when the database type is Db2 or PostgreSQL; the AE_DATABASE_USER set in the admin_secret_name is default when the database type is Oracle.
      current_schema: DBASB
      initial_pool_size: 1
      max_pool_size: 10
      uv_thread_pool_size: 4
      max_lru_cache_size: 1000
      max_lru_cache_age: 600000
      dbcompatibility_max_retries: 30
      dbcompatibility_retry_interval: 10
      ## The persistent volume claim for custom JDBC Drivers if using the custom JDBC drivers is enabled(use_custom_jdbc_drivers is true).
      custom_jdbc_pvc:
    log_level:
      node: info
      browser: 2
    content_security_policy:
      enable: false
      whitelist:
      frame_ancestor:
    env:
      max_size_lru_cache_rr: 1000
      server_env_type: development
      purge_stale_apps_interval: 86400000
      # Number of preview-only automation application must be more to trigger purge,
      apps_threshold: 100
      # Age of preview-only automation application since publish to be stale in milliseconds
      stale_threshold: 172800000
      # Number of preview-only automation services must be more to trigger purge,
      service_threshold: 100
      # Age of preview-only automation service since publish to be stale in milliseconds
      service_stale_threshold: 172800000
    max_age:
      auth_cookie: "900000"
      csrf_cookie: "3600000"
      static_asset: "2592000"
      hsts_header: "2592000"
    probe:
      liveness:
        failure_threshold: 5
        initial_delay_seconds: 60
        period_seconds: 10
        success_threshold: 1
        timeout_seconds: 180
      readiness:
        failure_threshold: 5
        initial_delay_seconds: 10
        period_seconds: 10
        success_threshold: 1
        timeout_seconds: 180
    #-----------------------------------------------------------------------
    # If you want better HA experience.
    # - Set the session.use_external_store to true
    # - Fill in your redis server information
    #-----------------------------------------------------------------------
    redis:
      # Your external redis host/ip
      host:
      # Your external redis port
      port: '6379'
      ttl: 1800
      # If your redis enabled TLS connection set this to true
      # You should add redis server CA certificate in tls_trust_list or trusted_certificate_list
      tls_enabled: false
    resource_ae:
      limits:
        cpu: 2000m
        memory: 2Gi
      requests:
        cpu: 300m
        memory: 512Mi
    resource_init:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
    session:
      check_period: "3600000"
      duration: "1800000"
      max: "10000"
      resave: "false"
      rolling: "true"
      save_uninitialized: "false"
      #-----------------------------------------------------------------------
      # If you want better HA experience.
      # - Set the session.use_external_store to true
      # - Fill in your redis server information
      #-----------------------------------------------------------------------
      use_external_store: "false"
    tls:
      tls_trust_list: []
    # If you want to make the replicate size more than 1 for this cluster. Then you must enable the shared storage
    share_storage:
      enabled: true
      # If you create the PV manually. Then please provide the PVC name bind here
      pvc_name:
      auto_provision:
        enabled: true
        # Required if you enabled the auto provision
        storage_class:
        size: 20Gi
  ########################################################################
  ########      IBM FileNet Content Manager configuration         ########
  ########################################################################
  ecm_configuration:
    ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
    ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
    fncm_secret_name: ibm-fncm-secret
    ## By default all the components create ingress and routes with required annotations. In case any custom annotation is needed for the environment provide below.
    #    route_ingress_annotations:
    #      - haproxy.router.openshift.io/balance: roundrobin
    route_ingress_annotations:
    ####################################
    ## Start of configuration for CPE ##
    ####################################
    cpe:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"
      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2
      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cpe
        tag: ga-556-p8cpe-la001
        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent
      ## Logging for workloads.  This is the default setting.
      log:
        format: json
      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 3072Mi
      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80
      ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cpe_production_setting:
        time_zone: Etc/UTC
        ## The initial use of available memory.
        jvm_initial_heap_percentage: 18
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 33
        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:
        ## Default JNDI name for GCD for non-XA data source
        gcd_jndi_name: FNGCDDS
        ## Default JNDI name for GCD for XA data source
        gcd_jndixa_name: FNGCDDSXA
        license_model: FNCM.PVUNonProd
        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept
      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false
      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false
      ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cpe_cfgstore: "cpe-cfgstore"
        existing_pvc_for_cpe_logstore: "cpe-logstore"
        existing_pvc_for_cpe_filestore: "cpe-filestore"
        existing_pvc_for_cpe_icmrulestore: "cpe-icmrulesstore"
        existing_pvc_for_cpe_textextstore: "cpe-textextstore"
        existing_pvc_for_cpe_bootstrapstore: "cpe-bootstrapstore"
        existing_pvc_for_cpe_fnlogstore: "cpe-fnlogstore"
      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 180
          period_seconds: 30
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 30
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"
    #####################################
    ## Start of configuration for CMIS ##
    #####################################
    cmis:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"
      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2
      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cmis
        tag: ga-305-cmis-if003
        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent
      ## Logging for workloads.  This is the default setting.
      log:
        format: json
      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 256Mi
        limits:
          cpu: 1
          memory: 1536Mi
      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80
      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cmis_production_setting:
        ## By default, this parameter is set by the Operator using the CPE service endpoint (e.g., "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM")
        cpe_url:
        time_zone: Etc/UTC
        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66
        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:
        ## Enable/disable Websphere Security
        ws_security_enabled: false
        # Enable/disable the content-stream of the Private Working Copy should be copied from the Document that was checked out.
        checkout_copycontent: true
        # The default value for the optional maxItems input argument on paging-related services.
        default_maxitems: 25
        # Enable/disable whether ChoiceLists will be cached once for all users.
        cvl_cache: true
        secure_metadata_cache: false
        # Enable/disalbe hidden P8 domain properties should appear in CMIS type definitions and folder or document instance data.
        filter_hidden_properties: true
        # Timeout in seconds for the queries that specify timeout.
        querytime_limit: 180
        # If true, then a faster response time for REST next line. If false, the next link for REST will re-issue query.
        resumable_queries_forrest: true
        # Specifies whether to escape characters that are not valid for XML unicode as specified by the XML 1.0 standard.
        escape_unsafe_string_characters: false
        # Limits the maximum allowable Web Service SOAP message request size.
        max_soap_size: 180
        # Enable/disable the printing of the full stack trace in the response.
        print_pull_stacktrace: false
        # Configures the sequence in which CMIS tries to identify objects (folder or document first).
        folder_first_search: false
        # To ignore the reading or writing contents in root folder, set this parameter to true.
        ignore_root_documents: false
        # Enable/disable the support type mutability.
        supporting_type_mutability: false
        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept
      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false
      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false
      ## Persistent Volume Claims for CMIS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cmis_cfgstore: "cmis-cfgstore"
        existing_pvc_for_cmis_logstore: "cmis-logstore"
      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 90
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 180
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"
    ########################################
    ## Start of configuration for GraphQL ##
    ########################################
    graphql:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"
      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2
      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/graphql
        tag: ga-556-p8cgql-if001
        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent
      ## Logging for workloads.  This is the default setting.
      log:
        format: json
      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1536Mi
      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        min_replicas: 2
        max_replicas: 3
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80
      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      graphql_production_setting:
        time_zone: Etc/UTC
        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66
        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:
        license_model: FNCM.PVUNonProd
        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept
        enable_graph_iql: false
        ## By default, this parameter is set by the Operator using the CPE service endpoint (e.g., "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM")
        cpe_uri:
      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false
      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false
      ## Persistent Volume Claims for GraphQL.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_graphql_cfgstore: "graphql-cfgstore"
        existing_pvc_for_graphql_logstore: "graphql-logstore"
      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 120
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"
